{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba942e14-18b0-407d-93b6-ddcac4b406ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd765525-8318-4d0d-a905-8355cfff3246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 15:54:08.822870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-22 15:54:08.822892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-22 15:54:08.823375: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49dc2af-eb7e-46bd-826f-88b9755ce151",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "dataset_path = '/home/deeplearning/AI/datasets/OpenWaste/Experimental-big-9/'\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "lr = 0.01\n",
    "weight_decay = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459d9bc9-7210-44d2-bece-7e212615c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed),\n",
    "    tf.keras.layers.RandomRotation(factor=0.05, seed=seed),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2, seed=seed)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa011333-be0f-4f85-8dde-13daf6d7df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(dataset_path + '/train', batch_size=batch_size)\n",
    "train_ds = train_ds_raw.map(lambda img, label: (data_augmentation(img), label)).shuffle(64, seed=seed).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14e8990-8c42-44c4-9fe4-322c40cccfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(dataset_path + '/val', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b70e853-3504-4114-b680-97632346ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds_raw.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124ca3d4-ee5e-419d-a1ed-968ce2b5b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B2(\n",
    "    weights=\"imagenet\", include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(avg)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.momentum = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aaff1d2-9e78-4462-bb71-debf79e98eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 15:54:16.838664: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711137259.939608  227052 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 16s 130ms/step - loss: 1.8804 - accuracy: 0.3703 - val_loss: 1.1877 - val_accuracy: 0.7647\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 3s 73ms/step - loss: 0.8562 - accuracy: 0.7784 - val_loss: 0.6693 - val_accuracy: 0.8235\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 3s 75ms/step - loss: 0.3914 - accuracy: 0.9216 - val_loss: 0.4713 - val_accuracy: 0.8758\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 3s 77ms/step - loss: 0.2010 - accuracy: 0.9459 - val_loss: 0.3998 - val_accuracy: 0.8954\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 3s 57ms/step - loss: 0.1477 - accuracy: 0.9676 - val_loss: 0.3755 - val_accuracy: 0.8954\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.1119 - accuracy: 0.9703 - val_loss: 0.3434 - val_accuracy: 0.8824\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 3s 57ms/step - loss: 0.0804 - accuracy: 0.9811 - val_loss: 0.3624 - val_accuracy: 0.8758\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0885 - accuracy: 0.9811 - val_loss: 0.3865 - val_accuracy: 0.8954\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0728 - accuracy: 0.9838 - val_loss: 0.3841 - val_accuracy: 0.8693\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 4s 81ms/step - loss: 0.0557 - accuracy: 0.9919 - val_loss: 0.3068 - val_accuracy: 0.9020\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 3s 53ms/step - loss: 0.0566 - accuracy: 0.9865 - val_loss: 0.3159 - val_accuracy: 0.8889\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 3s 59ms/step - loss: 0.0426 - accuracy: 0.9892 - val_loss: 0.3003 - val_accuracy: 0.9020\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 3s 53ms/step - loss: 0.0457 - accuracy: 0.9919 - val_loss: 0.3457 - val_accuracy: 0.9020\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0293 - accuracy: 0.9946 - val_loss: 0.3329 - val_accuracy: 0.9020\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.3712 - val_accuracy: 0.8889\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0273 - accuracy: 0.9973 - val_loss: 0.3443 - val_accuracy: 0.8889\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0474 - accuracy: 0.9838 - val_loss: 0.4306 - val_accuracy: 0.8824\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 3s 57ms/step - loss: 0.0339 - accuracy: 0.9946 - val_loss: 0.4112 - val_accuracy: 0.8758\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 3s 52ms/step - loss: 0.0322 - accuracy: 0.9919 - val_loss: 0.3442 - val_accuracy: 0.9020\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0394 - accuracy: 0.9838 - val_loss: 0.3363 - val_accuracy: 0.8954\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0278 - accuracy: 0.9973 - val_loss: 0.3561 - val_accuracy: 0.8954\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0522 - accuracy: 0.9865 - val_loss: 0.3871 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0419 - accuracy: 0.9919 - val_loss: 0.4477 - val_accuracy: 0.8366\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.4004 - val_accuracy: 0.8693\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 0.3561 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0365 - accuracy: 0.9865 - val_loss: 0.4495 - val_accuracy: 0.8824\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0319 - accuracy: 0.9946 - val_loss: 0.4323 - val_accuracy: 0.8824\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 3s 57ms/step - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.3620 - val_accuracy: 0.8954\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.4165 - val_accuracy: 0.8758\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.3834 - val_accuracy: 0.8693\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.3803 - val_accuracy: 0.8954\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0230 - accuracy: 0.9946 - val_loss: 0.3225 - val_accuracy: 0.8954\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.3966 - val_accuracy: 0.8627\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0338 - accuracy: 0.9946 - val_loss: 0.3614 - val_accuracy: 0.8954\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0168 - accuracy: 0.9919 - val_loss: 0.3618 - val_accuracy: 0.8954\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0316 - accuracy: 0.9973 - val_loss: 0.3844 - val_accuracy: 0.8758\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.3573 - val_accuracy: 0.8954\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.3826 - val_accuracy: 0.8627\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.3913 - val_accuracy: 0.8758\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 3s 59ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8889\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 3s 53ms/step - loss: 0.0211 - accuracy: 0.9892 - val_loss: 0.3876 - val_accuracy: 0.8954\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.8758\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 3s 57ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.3978 - val_accuracy: 0.8954\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 3s 59ms/step - loss: 0.0208 - accuracy: 0.9919 - val_loss: 0.3569 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 3s 59ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9020\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0463 - accuracy: 0.9892 - val_loss: 0.4964 - val_accuracy: 0.8824\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 3s 55ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.5400 - val_accuracy: 0.8758\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 3s 58ms/step - loss: 0.0488 - accuracy: 0.9865 - val_loss: 0.4158 - val_accuracy: 0.8758\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 3s 56ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.3837 - val_accuracy: 0.8954\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 3s 54ms/step - loss: 0.0318 - accuracy: 0.9946 - val_loss: 0.4147 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/efficientnet_v2_open_waste.keras',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "    \n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e998745-5346-4edc-9065-45910e61d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x721c0827fdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = 'models/efficientnet_v2_open_waste.keras' #model_checkpoint_callback.filepath\n",
    "saved_model = tf.keras.models.load_model(saved_model_path)\n",
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1b21fc-66e0-4b33-92ff-b3cdc8c62fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 22ms/step - loss: 0.3068 - accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3068206012248993, 0.9019607901573181]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3186f599-7482-4011-9bad-b024124d3ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(dataset_path + '/val', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ba6bb4-99c6-477d-8696-b10c2f7cf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 11ms/step - loss: 0.3068 - accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3068210482597351, 0.9019607901573181]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9bf606e-57cb-49c6-9c81-d05f1b84deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for X, y in test_ds:\n",
    "    y_pred = tf.argmax(saved_model.predict(X, verbose=0), axis=1).numpy().tolist()\n",
    "    labels.extend(y.numpy().tolist())\n",
    "    predictions.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4937c5ad-0f9d-4a70-ad5c-c3a5629fbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "          Cardboard CORRUGATED box       0.83      0.33      0.48        15\n",
      "               Metal TIN container       0.80      1.00      0.89        12\n",
      "Paper COATED PAPERBOARD coffee cup       0.82      1.00      0.90        14\n",
      "    Plastic ALUMINUM LINED wrapper       0.80      0.89      0.84        18\n",
      "     Plastic TYPE 1 food container       0.94      0.97      0.95        30\n",
      "                Plastic TYPE 4 bag       0.93      1.00      0.97        14\n",
      "    Plastic TYPE 5 sauce container       1.00      0.93      0.96        14\n",
      "         Plastic TYPE 6 coffee lid       0.94      0.94      0.94        18\n",
      " Plastic TYPE 6 straws and cutlery       1.00      1.00      1.00        18\n",
      "\n",
      "                          accuracy                           0.90       153\n",
      "                         macro avg       0.90      0.90      0.88       153\n",
      "                      weighted avg       0.90      0.90      0.89       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, predictions, target_names=test_ds.class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
