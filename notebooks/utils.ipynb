{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0274758b-478b-456f-ae44-a55c5ddbdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ede47ff1-e454-4eeb-b8f1-e5db0cbf9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(file_name):\n",
    "    img_list = {}\n",
    "    with open(file_name) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        img_list[values[0]] = int(values[1])\n",
    "\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f43f01f5-ba48-4794-8228-cac654cdca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_directories = ['glass', 'paper', 'cardboard', 'plastic', 'metal', 'trash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846d56a7-822b-4154-b8bc-64d617596a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(images_path, images_new_path, image_name, class_index):\n",
    "    img_path = Path(images_path) / class_directories[class_index] / Path(image_name)\n",
    "    img_new_path = Path(images_new_path) / class_directories[class_index] / Path(image_name)\n",
    "\n",
    "    shutil.copy(img_path, img_new_path)\n",
    "\n",
    "    return str(img_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18a6b2d8-f9cd-4731-91a0-e136fa74303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/home/deeplearning/AI/projects/trashnet/data/dataset-resized/'\n",
    "images_new_path = '/home/deeplearning/AI/datasets/TrashNet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76874931-6c4a-4500-b004-96e4fad0471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = get_img_list('/home/deeplearning/AI/projects/trashnet/data/one-indexed-files-notrash_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66961aba-e7f6-4a9d-bc53-97f956cb5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, class_index in train_list.items():\n",
    "    copy_images(images_path, images_new_path + '/train', img_name, class_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05563038-22f4-45ac-8c61-2100b58d36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = get_img_list('/home/deeplearning/AI/projects/trashnet/data/one-indexed-files-notrash_val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9ca42e6-802e-4cb7-ac3f-9b4c777afbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, class_index in val_list.items():\n",
    "    copy_images(images_path, images_new_path + '/val', img_name, class_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aad7e551-8351-4966-b779-9cd1fd38e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = get_img_list('/home/deeplearning/AI/projects/trashnet/data/one-indexed-files-notrash_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "699bc521-c093-4d44-8df9-856b03ac46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, class_index in test_list.items():\n",
    "    copy_images(images_path, images_new_path + '/test', img_name, class_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "431a1dd0-5bbe-43ea-b682-bff78d2c25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "from PIL import Image\n",
    "\n",
    "def check_imgs(dataset_path):\n",
    "    files_count = 0\n",
    "    img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "    for filepath in Path(dataset_path).rglob(\"*\"):\n",
    "        try:\n",
    "            if filepath.is_file():\n",
    "                img_type = imghdr.what(filepath)\n",
    "                img = Image.open(filepath) \n",
    "                    # img = Image.open(filepath) \n",
    "                    # img = img.convert('RGB')\n",
    "                    # img.save(filepath)\n",
    "                if img_type is None:\n",
    "                    # filepath.rename(dataset_path + '/val_deleted/' + filepath.name)\n",
    "                    files_count += 1\n",
    "                    print(f\"{filepath} is not an image\")\n",
    "                elif img_type not in img_type_accepted_by_tf:\n",
    "                    files_count += 1\n",
    "                    # filepath.rename(dataset_path + '/val_deleted/' + filepath.name)    \n",
    "                    print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "        except:\n",
    "            print(f\"Cannot open {filepath}\")\n",
    "\n",
    "    return files_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0939f375-984a-4d05-bc02-0be95b6153ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open /home/deeplearning/AI/datasets/TrashBox-Old/test_deleted/paper 42.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_imgs('/home/deeplearning/AI/datasets/TrashBox-Old/test_deleted/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14cad32b-3f68-46a2-ae7f-63b9c14f7e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 11:54:11.675517: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 11:54:11.693598: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 11:54:11.693616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 11:54:11.694096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-15 11:54:11.697161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 11:54:12.026022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df0f29d-abe2-4dab-891d-1dd0d16bbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2339ba75-bb71-4044-9891-ca83bc9fcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2B2(input_shape=(260, 260, 3), weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdcd8508-449a-4e8e-a6fa-4bfc584741a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20c99d19-3456-4714-982f-608f7577ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daa1647d-d976-43df-af9b-79b1da1a5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1, 260, 260, 3)\n",
    "model(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69114935-2a48-43a9-a9a0-3768db7d0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7e470c-cca0-492d-a239-cc13673d6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_waste_path = Path('/home/deeplearning/AI/datasets/OpenWaste/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0dd9b1b-77ea-4f89-a421-a16f00b6674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c611494-e267-4e89-9634-ee74a757cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aluminum foil',\n",
       " 'metal and plastic film',\n",
       " 'plastic other',\n",
       " 'plastic food package (not stretchy)',\n",
       " 'plastic cleaning product bottle #5',\n",
       " 'cardboard toilet paper roll',\n",
       " 'plastic straws and cutlery #6',\n",
       " 'paper napkin',\n",
       " 'paper receipt (thermal paper)',\n",
       " 'paper wrapping (unwaxed)',\n",
       " 'plastic bottle cap #5',\n",
       " 'plastic wrap (stretchy)',\n",
       " 'paper bag',\n",
       " 'milk carton (coated paper)',\n",
       " 'plastic food container #1',\n",
       " 'cardboard food box',\n",
       " 'plastic sauce container #5',\n",
       " 'plastic bag',\n",
       " 'plastic coffee cup lid #6',\n",
       " 'plastic yogurt lid #5',\n",
       " 'plastic yogurt container #5',\n",
       " 'plastic food container #6',\n",
       " 'paper wrapping (waxed)',\n",
       " 'paper - office paper, catalogues, tags, envelopes, newspaper, wrapping paper',\n",
       " 'plastic tab #6',\n",
       " 'fruit and vegetable scrap',\n",
       " 'paper coffee cup sleeve',\n",
       " 'plastic tea bag',\n",
       " 'cardboard box',\n",
       " 'paper tag (waxed)',\n",
       " 'plastic food container #7',\n",
       " 'metal tin can',\n",
       " 'plastic bottle #5',\n",
       " 'paper towel',\n",
       " 'paper coffee cup (coated paperboard)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = next(iter(os.walk(open_waste_path)))[1]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2598f6c0-c766-4e4d-b6b3-b1682f023d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3298c89-06a4-4e87-a75b-760db71f5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory, dirname, files in os.walk(open_waste_path):\n",
    "    category = directory[len(str(open_waste_path))+1:]\n",
    "    if len(category) > 0:\n",
    "        stats[category] += len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbba1992-b58a-4209-8078-bc2b66944172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 1,\n",
       "             'aluminum foil': 4,\n",
       "             'metal and plastic film': 15,\n",
       "             'plastic other': 4,\n",
       "             'plastic food package (not stretchy)': 4,\n",
       "             'plastic cleaning product bottle #5': 4,\n",
       "             'cardboard toilet paper roll': 5,\n",
       "             'plastic straws and cutlery #6': 5,\n",
       "             'paper napkin': 5,\n",
       "             'paper receipt (thermal paper)': 7,\n",
       "             'paper wrapping (unwaxed)': 3,\n",
       "             'plastic bottle cap #5': 6,\n",
       "             'plastic wrap (stretchy)': 8,\n",
       "             'paper bag': 9,\n",
       "             'milk carton (coated paper)': 5,\n",
       "             'plastic food container #1': 23,\n",
       "             'cardboard food box': 12,\n",
       "             'plastic sauce container #5': 5,\n",
       "             'plastic bag': 20,\n",
       "             'plastic coffee cup lid #6': 6,\n",
       "             'plastic yogurt lid #5': 4,\n",
       "             'plastic yogurt container #5': 6,\n",
       "             'plastic food container #6': 3,\n",
       "             'paper wrapping (waxed)': 7,\n",
       "             'paper - office paper, catalogues, tags, envelopes, newspaper, wrapping paper': 12,\n",
       "             'plastic tab #6': 5,\n",
       "             'fruit and vegetable scrap': 9,\n",
       "             'paper coffee cup sleeve': 4,\n",
       "             'plastic tea bag': 3,\n",
       "             'cardboard box': 9,\n",
       "             'paper tag (waxed)': 7,\n",
       "             'plastic food container #7': 13,\n",
       "             'metal tin can': 4,\n",
       "             'plastic bottle #5': 6,\n",
       "             'paper towel': 4,\n",
       "             'paper coffee cup (coated paperboard)': 10})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ad8d3de-32cb-45d8-9190-bd7984a69b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "982acc4c-ac68-4c86-9955-96c21a867cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/home/deeplearning/AI/datasets/TrashBox-Old/test_deleted/'\n",
    "image_files = [path.join(images_path, f) for f in os.listdir(images_path) if path.isfile(path.join(images_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c07f27e-efa6-4334-a819-245e7f5993ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.9.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_image_count = 0\n",
    "for f in image_files:\n",
    "    try:\n",
    "        img = cv2.imread(f);\n",
    "        cv2.imwrite(f, img)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        non_image_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f156f2a-1dd2-4f99-9f68-27fab2170d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7d934-e398-47f3-8f25-6ee6010dd036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
